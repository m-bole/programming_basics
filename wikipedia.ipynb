{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfUNQ0S-MjXK",
        "outputId": "8a46384c-5811-4b97-f436-2441efe70b51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# Step 1: Load SpaCy's large English language model\n",
        "!python -m spacy download en_core_web_lg\n",
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 2: Load the introduction and content from .txt files\n",
        "intro_file_path = \"intro.txt\"  # Replace with your actual file path\n",
        "content_file_path = \"text.txt\"  # Replace with your actual file path\n",
        "\n",
        "with open(intro_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    introduction = f.read()\n",
        "\n",
        "with open(content_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    content = f.read()\n"
      ],
      "metadata": {
        "id": "Nca6k3ZoMmTR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3a: Tokenize introduction and print each token and its lemma\n",
        "print(\"\\n--- Tokens and Lemmas in Introduction ---\")\n",
        "intro_doc = nlp(introduction)\n",
        "for token in intro_doc:\n",
        "    print(f\"Token: {token.text}, Lemma: {token.lemma_}\")\n",
        "\n",
        "# Step 3b: Print each token and its Part-of-Speech (POS)\n",
        "print(\"\\n--- Tokens and POS in Introduction ---\")\n",
        "for token in intro_doc:\n",
        "    print(f\"Token: {token.text}, POS: {token.pos_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmSYyvnpM3Yh",
        "outputId": "18a5c836-b6ff-4b53-b477-6653a2859378"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Tokens and Lemmas in Introduction ---\n",
            "Token: Hyraxes, Lemma: Hyraxes\n",
            "Token: (, Lemma: (\n",
            "Token: from, Lemma: from\n",
            "Token: Ancient, Lemma: ancient\n",
            "Token: Greek, Lemma: greek\n",
            "Token: ὕραξ, Lemma: ὕραξ\n",
            "Token: hýrax, Lemma: hýrax\n",
            "Token: ', Lemma: '\n",
            "Token: shrew, Lemma: shrew\n",
            "Token: -, Lemma: -\n",
            "Token: mouse, Lemma: mouse\n",
            "Token: ', Lemma: '\n",
            "Token: ), Lemma: )\n",
            "Token: ,, Lemma: ,\n",
            "Token: also, Lemma: also\n",
            "Token: called, Lemma: call\n",
            "Token: dassies,[1][2, Lemma: dassies,[1][2\n",
            "Token: ], Lemma: ]\n",
            "Token: are, Lemma: be\n",
            "Token: small, Lemma: small\n",
            "Token: ,, Lemma: ,\n",
            "Token: stout, Lemma: stout\n",
            "Token: ,, Lemma: ,\n",
            "Token: thickset, Lemma: thickset\n",
            "Token: ,, Lemma: ,\n",
            "Token: herbivorous, Lemma: herbivorous\n",
            "Token: mammals, Lemma: mammal\n",
            "Token: in, Lemma: in\n",
            "Token: the, Lemma: the\n",
            "Token: family, Lemma: family\n",
            "Token: Procaviidae, Lemma: Procaviidae\n",
            "Token: within, Lemma: within\n",
            "Token: the, Lemma: the\n",
            "Token: order, Lemma: order\n",
            "Token: Hyracoidea, Lemma: Hyracoidea\n",
            "Token: ., Lemma: .\n",
            "Token: Hyraxes, Lemma: Hyraxes\n",
            "Token: are, Lemma: be\n",
            "Token: well, Lemma: well\n",
            "Token: -, Lemma: -\n",
            "Token: furred, Lemma: fur\n",
            "Token: ,, Lemma: ,\n",
            "Token: rotund, Lemma: rotund\n",
            "Token: animals, Lemma: animal\n",
            "Token: with, Lemma: with\n",
            "Token: short, Lemma: short\n",
            "Token: tails.[3, Lemma: tails.[3\n",
            "Token: ], Lemma: ]\n",
            "Token: Modern, Lemma: modern\n",
            "Token: hyraxes, Lemma: hyrax\n",
            "Token: are, Lemma: be\n",
            "Token: typically, Lemma: typically\n",
            "Token: between, Lemma: between\n",
            "Token: 30, Lemma: 30\n",
            "Token: and, Lemma: and\n",
            "Token: 70, Lemma: 70\n",
            "Token: cm, Lemma: cm\n",
            "Token: (, Lemma: (\n",
            "Token: 12, Lemma: 12\n",
            "Token: and, Lemma: and\n",
            "Token: 28, Lemma: 28\n",
            "Token: in, Lemma: in\n",
            "Token: ), Lemma: )\n",
            "Token: in, Lemma: in\n",
            "Token: length, Lemma: length\n",
            "Token: and, Lemma: and\n",
            "Token: weigh, Lemma: weigh\n",
            "Token: between, Lemma: between\n",
            "Token: 2, Lemma: 2\n",
            "Token: and, Lemma: and\n",
            "Token: 5, Lemma: 5\n",
            "Token: kg, Lemma: kg\n",
            "Token: (, Lemma: (\n",
            "Token: 4, Lemma: 4\n",
            "Token: and, Lemma: and\n",
            "Token: 11, Lemma: 11\n",
            "Token: lb, Lemma: lb\n",
            "Token: ), Lemma: )\n",
            "Token: ., Lemma: .\n",
            "Token: They, Lemma: they\n",
            "Token: are, Lemma: be\n",
            "Token: superficially, Lemma: superficially\n",
            "Token: similar, Lemma: similar\n",
            "Token: to, Lemma: to\n",
            "Token: marmots, Lemma: marmot\n",
            "Token: ,, Lemma: ,\n",
            "Token: or, Lemma: or\n",
            "Token: over, Lemma: over\n",
            "Token: -, Lemma: -\n",
            "Token: large, Lemma: large\n",
            "Token: pikas, Lemma: pikas\n",
            "Token: ,, Lemma: ,\n",
            "Token: but, Lemma: but\n",
            "Token: are, Lemma: be\n",
            "Token: much, Lemma: much\n",
            "Token: more, Lemma: more\n",
            "Token: closely, Lemma: closely\n",
            "Token: related, Lemma: related\n",
            "Token: to, Lemma: to\n",
            "Token: elephants, Lemma: elephant\n",
            "Token: and, Lemma: and\n",
            "Token: sirenians, Lemma: sirenian\n",
            "Token: ., Lemma: .\n",
            "Token: Hyraxes, Lemma: Hyraxes\n",
            "Token: have, Lemma: have\n",
            "Token: a, Lemma: a\n",
            "Token: life, Lemma: life\n",
            "Token: span, Lemma: span\n",
            "Token: from, Lemma: from\n",
            "Token: nine, Lemma: nine\n",
            "Token: to, Lemma: to\n",
            "Token: 14, Lemma: 14\n",
            "Token: years, Lemma: year\n",
            "Token: ., Lemma: .\n",
            "Token: Both, Lemma: both\n",
            "Token: types, Lemma: type\n",
            "Token: of, Lemma: of\n",
            "Token: \", Lemma: \"\n",
            "Token: rock, Lemma: rock\n",
            "Token: \", Lemma: \"\n",
            "Token: hyrax, Lemma: hyrax\n",
            "Token: (, Lemma: (\n",
            "Token: P., Lemma: P.\n",
            "Token: capensis, Lemma: capensis\n",
            "Token: and, Lemma: and\n",
            "Token: H., Lemma: H.\n",
            "Token: brucei, Lemma: brucei\n",
            "Token: ), Lemma: )\n",
            "Token: live, Lemma: live\n",
            "Token: on, Lemma: on\n",
            "Token: rock, Lemma: rock\n",
            "Token: outcrops, Lemma: outcrop\n",
            "Token: ,, Lemma: ,\n",
            "Token: including, Lemma: include\n",
            "Token: cliffs, Lemma: cliff\n",
            "Token: in, Lemma: in\n",
            "Token: Ethiopia[4, Lemma: Ethiopia[4\n",
            "Token: ], Lemma: ]\n",
            "Token: and, Lemma: and\n",
            "Token: isolated, Lemma: isolated\n",
            "Token: granite, Lemma: granite\n",
            "Token: outcrops, Lemma: outcrop\n",
            "Token: called, Lemma: call\n",
            "Token: koppies, Lemma: koppie\n",
            "Token: in, Lemma: in\n",
            "Token: southern, Lemma: southern\n",
            "Token: Africa.[5, Lemma: Africa.[5\n",
            "Token: ], Lemma: ]\n",
            "Token: \n",
            "\n",
            ", Lemma: \n",
            "\n",
            "\n",
            "Token: With, Lemma: with\n",
            "Token: one, Lemma: one\n",
            "Token: exception, Lemma: exception\n",
            "Token: ,, Lemma: ,\n",
            "Token: all, Lemma: all\n",
            "Token: hyraxes, Lemma: hyrax\n",
            "Token: are, Lemma: be\n",
            "Token: limited, Lemma: limit\n",
            "Token: to, Lemma: to\n",
            "Token: Africa, Lemma: Africa\n",
            "Token: ;, Lemma: ;\n",
            "Token: the, Lemma: the\n",
            "Token: exception, Lemma: exception\n",
            "Token: is, Lemma: be\n",
            "Token: the, Lemma: the\n",
            "Token: rock, Lemma: rock\n",
            "Token: hyrax, Lemma: hyrax\n",
            "Token: (, Lemma: (\n",
            "Token: P., Lemma: P.\n",
            "Token: capensis, Lemma: capensis\n",
            "Token: ), Lemma: )\n",
            "Token: which, Lemma: which\n",
            "Token: is, Lemma: be\n",
            "Token: also, Lemma: also\n",
            "Token: found, Lemma: find\n",
            "Token: in, Lemma: in\n",
            "Token: adjacent, Lemma: adjacent\n",
            "Token: parts, Lemma: part\n",
            "Token: of, Lemma: of\n",
            "Token: the, Lemma: the\n",
            "Token: Middle, Lemma: Middle\n",
            "Token: East, Lemma: East\n",
            "Token: ., Lemma: .\n",
            "Token: \n",
            "\n",
            ", Lemma: \n",
            "\n",
            "\n",
            "Token: Hyraxes, Lemma: Hyraxes\n",
            "Token: were, Lemma: be\n",
            "Token: a, Lemma: a\n",
            "Token: much, Lemma: much\n",
            "Token: more, Lemma: more\n",
            "Token: diverse, Lemma: diverse\n",
            "Token: group, Lemma: group\n",
            "Token: in, Lemma: in\n",
            "Token: the, Lemma: the\n",
            "Token: past, Lemma: past\n",
            "Token: encompassing, Lemma: encompass\n",
            "Token: species, Lemma: specie\n",
            "Token: considerably, Lemma: considerably\n",
            "Token: larger, Lemma: large\n",
            "Token: than, Lemma: than\n",
            "Token: modern, Lemma: modern\n",
            "Token: hyraxes, Lemma: hyrax\n",
            "Token: ., Lemma: .\n",
            "Token: The, Lemma: the\n",
            "Token: largest, Lemma: largest\n",
            "Token: known, Lemma: known\n",
            "Token: extinct, Lemma: extinct\n",
            "Token: hyrax, Lemma: hyrax\n",
            "Token: ,, Lemma: ,\n",
            "Token: Titanohyrax, Lemma: Titanohyrax\n",
            "Token: ultimus, Lemma: ultimus\n",
            "Token: ,, Lemma: ,\n",
            "Token: has, Lemma: have\n",
            "Token: been, Lemma: be\n",
            "Token: estimated, Lemma: estimate\n",
            "Token: to, Lemma: to\n",
            "Token: weigh, Lemma: weigh\n",
            "Token: 600–1,300, Lemma: 600–1,300\n",
            "Token: kilograms, Lemma: kilogram\n",
            "Token: (, Lemma: (\n",
            "Token: 1,300–2,900, Lemma: 1,300–2,900\n",
            "Token: lb, Lemma: lb\n",
            "Token: ), Lemma: )\n",
            "Token: ,, Lemma: ,\n",
            "Token: comparable, Lemma: comparable\n",
            "Token: to, Lemma: to\n",
            "Token: a, Lemma: a\n",
            "Token: rhinoceros.[6, Lemma: rhinoceros.[6\n",
            "Token: ], Lemma: ]\n",
            "Token: \n",
            "\n",
            ", Lemma: \n",
            "\n",
            "\n",
            "\n",
            "--- Tokens and POS in Introduction ---\n",
            "Token: Hyraxes, POS: PROPN\n",
            "Token: (, POS: PUNCT\n",
            "Token: from, POS: ADP\n",
            "Token: Ancient, POS: ADJ\n",
            "Token: Greek, POS: ADJ\n",
            "Token: ὕραξ, POS: NOUN\n",
            "Token: hýrax, POS: PROPN\n",
            "Token: ', POS: PUNCT\n",
            "Token: shrew, POS: NOUN\n",
            "Token: -, POS: PUNCT\n",
            "Token: mouse, POS: PROPN\n",
            "Token: ', POS: PUNCT\n",
            "Token: ), POS: PUNCT\n",
            "Token: ,, POS: PUNCT\n",
            "Token: also, POS: ADV\n",
            "Token: called, POS: VERB\n",
            "Token: dassies,[1][2, POS: PROPN\n",
            "Token: ], POS: PUNCT\n",
            "Token: are, POS: AUX\n",
            "Token: small, POS: ADJ\n",
            "Token: ,, POS: PUNCT\n",
            "Token: stout, POS: ADJ\n",
            "Token: ,, POS: PUNCT\n",
            "Token: thickset, POS: ADJ\n",
            "Token: ,, POS: PUNCT\n",
            "Token: herbivorous, POS: ADJ\n",
            "Token: mammals, POS: NOUN\n",
            "Token: in, POS: ADP\n",
            "Token: the, POS: DET\n",
            "Token: family, POS: NOUN\n",
            "Token: Procaviidae, POS: PROPN\n",
            "Token: within, POS: ADP\n",
            "Token: the, POS: DET\n",
            "Token: order, POS: NOUN\n",
            "Token: Hyracoidea, POS: PROPN\n",
            "Token: ., POS: PUNCT\n",
            "Token: Hyraxes, POS: PROPN\n",
            "Token: are, POS: AUX\n",
            "Token: well, POS: ADV\n",
            "Token: -, POS: PUNCT\n",
            "Token: furred, POS: VERB\n",
            "Token: ,, POS: PUNCT\n",
            "Token: rotund, POS: ADJ\n",
            "Token: animals, POS: NOUN\n",
            "Token: with, POS: ADP\n",
            "Token: short, POS: ADJ\n",
            "Token: tails.[3, POS: X\n",
            "Token: ], POS: X\n",
            "Token: Modern, POS: ADJ\n",
            "Token: hyraxes, POS: NOUN\n",
            "Token: are, POS: AUX\n",
            "Token: typically, POS: ADV\n",
            "Token: between, POS: ADP\n",
            "Token: 30, POS: NUM\n",
            "Token: and, POS: CCONJ\n",
            "Token: 70, POS: NUM\n",
            "Token: cm, POS: NOUN\n",
            "Token: (, POS: PUNCT\n",
            "Token: 12, POS: NUM\n",
            "Token: and, POS: CCONJ\n",
            "Token: 28, POS: NUM\n",
            "Token: in, POS: ADP\n",
            "Token: ), POS: PUNCT\n",
            "Token: in, POS: ADP\n",
            "Token: length, POS: NOUN\n",
            "Token: and, POS: CCONJ\n",
            "Token: weigh, POS: VERB\n",
            "Token: between, POS: ADP\n",
            "Token: 2, POS: NUM\n",
            "Token: and, POS: CCONJ\n",
            "Token: 5, POS: NUM\n",
            "Token: kg, POS: NOUN\n",
            "Token: (, POS: PUNCT\n",
            "Token: 4, POS: NUM\n",
            "Token: and, POS: CCONJ\n",
            "Token: 11, POS: NUM\n",
            "Token: lb, POS: NOUN\n",
            "Token: ), POS: PUNCT\n",
            "Token: ., POS: PUNCT\n",
            "Token: They, POS: PRON\n",
            "Token: are, POS: AUX\n",
            "Token: superficially, POS: ADV\n",
            "Token: similar, POS: ADJ\n",
            "Token: to, POS: ADP\n",
            "Token: marmots, POS: NOUN\n",
            "Token: ,, POS: PUNCT\n",
            "Token: or, POS: CCONJ\n",
            "Token: over, POS: ADV\n",
            "Token: -, POS: PUNCT\n",
            "Token: large, POS: ADJ\n",
            "Token: pikas, POS: PROPN\n",
            "Token: ,, POS: PUNCT\n",
            "Token: but, POS: CCONJ\n",
            "Token: are, POS: AUX\n",
            "Token: much, POS: ADV\n",
            "Token: more, POS: ADV\n",
            "Token: closely, POS: ADV\n",
            "Token: related, POS: ADJ\n",
            "Token: to, POS: ADP\n",
            "Token: elephants, POS: NOUN\n",
            "Token: and, POS: CCONJ\n",
            "Token: sirenians, POS: NOUN\n",
            "Token: ., POS: PUNCT\n",
            "Token: Hyraxes, POS: PROPN\n",
            "Token: have, POS: VERB\n",
            "Token: a, POS: DET\n",
            "Token: life, POS: NOUN\n",
            "Token: span, POS: NOUN\n",
            "Token: from, POS: ADP\n",
            "Token: nine, POS: NUM\n",
            "Token: to, POS: PART\n",
            "Token: 14, POS: NUM\n",
            "Token: years, POS: NOUN\n",
            "Token: ., POS: PUNCT\n",
            "Token: Both, POS: DET\n",
            "Token: types, POS: NOUN\n",
            "Token: of, POS: ADP\n",
            "Token: \", POS: PUNCT\n",
            "Token: rock, POS: NOUN\n",
            "Token: \", POS: PUNCT\n",
            "Token: hyrax, POS: NOUN\n",
            "Token: (, POS: PUNCT\n",
            "Token: P., POS: PROPN\n",
            "Token: capensis, POS: NOUN\n",
            "Token: and, POS: CCONJ\n",
            "Token: H., POS: PROPN\n",
            "Token: brucei, POS: PROPN\n",
            "Token: ), POS: PUNCT\n",
            "Token: live, POS: VERB\n",
            "Token: on, POS: ADP\n",
            "Token: rock, POS: NOUN\n",
            "Token: outcrops, POS: NOUN\n",
            "Token: ,, POS: PUNCT\n",
            "Token: including, POS: VERB\n",
            "Token: cliffs, POS: NOUN\n",
            "Token: in, POS: ADP\n",
            "Token: Ethiopia[4, POS: PROPN\n",
            "Token: ], POS: PUNCT\n",
            "Token: and, POS: CCONJ\n",
            "Token: isolated, POS: ADJ\n",
            "Token: granite, POS: NOUN\n",
            "Token: outcrops, POS: NOUN\n",
            "Token: called, POS: VERB\n",
            "Token: koppies, POS: NOUN\n",
            "Token: in, POS: ADP\n",
            "Token: southern, POS: ADJ\n",
            "Token: Africa.[5, POS: PROPN\n",
            "Token: ], POS: PUNCT\n",
            "Token: \n",
            "\n",
            ", POS: SPACE\n",
            "Token: With, POS: ADP\n",
            "Token: one, POS: NUM\n",
            "Token: exception, POS: NOUN\n",
            "Token: ,, POS: PUNCT\n",
            "Token: all, POS: DET\n",
            "Token: hyraxes, POS: NOUN\n",
            "Token: are, POS: AUX\n",
            "Token: limited, POS: VERB\n",
            "Token: to, POS: ADP\n",
            "Token: Africa, POS: PROPN\n",
            "Token: ;, POS: PUNCT\n",
            "Token: the, POS: DET\n",
            "Token: exception, POS: NOUN\n",
            "Token: is, POS: AUX\n",
            "Token: the, POS: DET\n",
            "Token: rock, POS: NOUN\n",
            "Token: hyrax, POS: NOUN\n",
            "Token: (, POS: PUNCT\n",
            "Token: P., POS: PROPN\n",
            "Token: capensis, POS: NOUN\n",
            "Token: ), POS: PUNCT\n",
            "Token: which, POS: PRON\n",
            "Token: is, POS: AUX\n",
            "Token: also, POS: ADV\n",
            "Token: found, POS: VERB\n",
            "Token: in, POS: ADP\n",
            "Token: adjacent, POS: ADJ\n",
            "Token: parts, POS: NOUN\n",
            "Token: of, POS: ADP\n",
            "Token: the, POS: DET\n",
            "Token: Middle, POS: PROPN\n",
            "Token: East, POS: PROPN\n",
            "Token: ., POS: PUNCT\n",
            "Token: \n",
            "\n",
            ", POS: SPACE\n",
            "Token: Hyraxes, POS: PROPN\n",
            "Token: were, POS: AUX\n",
            "Token: a, POS: DET\n",
            "Token: much, POS: ADV\n",
            "Token: more, POS: ADV\n",
            "Token: diverse, POS: ADJ\n",
            "Token: group, POS: NOUN\n",
            "Token: in, POS: ADP\n",
            "Token: the, POS: DET\n",
            "Token: past, POS: NOUN\n",
            "Token: encompassing, POS: VERB\n",
            "Token: species, POS: NOUN\n",
            "Token: considerably, POS: ADV\n",
            "Token: larger, POS: ADJ\n",
            "Token: than, POS: ADP\n",
            "Token: modern, POS: ADJ\n",
            "Token: hyraxes, POS: NOUN\n",
            "Token: ., POS: PUNCT\n",
            "Token: The, POS: DET\n",
            "Token: largest, POS: ADV\n",
            "Token: known, POS: ADJ\n",
            "Token: extinct, POS: ADJ\n",
            "Token: hyrax, POS: NOUN\n",
            "Token: ,, POS: PUNCT\n",
            "Token: Titanohyrax, POS: PROPN\n",
            "Token: ultimus, POS: NOUN\n",
            "Token: ,, POS: PUNCT\n",
            "Token: has, POS: AUX\n",
            "Token: been, POS: AUX\n",
            "Token: estimated, POS: VERB\n",
            "Token: to, POS: PART\n",
            "Token: weigh, POS: VERB\n",
            "Token: 600–1,300, POS: NUM\n",
            "Token: kilograms, POS: NOUN\n",
            "Token: (, POS: PUNCT\n",
            "Token: 1,300–2,900, POS: NUM\n",
            "Token: lb, POS: NOUN\n",
            "Token: ), POS: PUNCT\n",
            "Token: ,, POS: PUNCT\n",
            "Token: comparable, POS: ADJ\n",
            "Token: to, POS: ADP\n",
            "Token: a, POS: DET\n",
            "Token: rhinoceros.[6, POS: NOUN\n",
            "Token: ], POS: PUNCT\n",
            "Token: \n",
            "\n",
            ", POS: SPACE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 4: Perform NER on the content and display people, places, and organizations\n",
        "print(\"\\n--- Named Entities in Content ---\")\n",
        "content_doc = nlp(content)\n",
        "entities = {\"PERSON\": [], \"GPE\": [], \"ORG\": []}\n",
        "\n",
        "for ent in content_doc.ents:\n",
        "    if ent.label_ in entities:\n",
        "        entities[ent.label_].append(ent.text)\n",
        "\n",
        "# Remove duplicates\n",
        "entities = {key: list(set(value)) for key, value in entities.items()}\n",
        "\n",
        "print(\"\\nPeople:\", entities[\"PERSON\"])\n",
        "print(\"\\nPlaces (GPE):\", entities[\"GPE\"])\n",
        "print(\"\\nOrganizations:\", entities[\"ORG\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nmh39OwM5Ad",
        "outputId": "c12d8a0d-700b-4236-cfcc-05ee274cc126"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Named Entities in Content ---\n",
            "\n",
            "People: ['Tree hyrax', 'Pachyhyrax', 'Procaviidae \\u2003\\t\\n\\u2003\\t\\n\\u2003 Dendrohyrax \\u2003\\t\\n\\u2003\\t\\nSouthern', '†Antilohyrax\\n†Rupestrohyrax', 'Strabo', '†Meroehyrax\\n', 'Archaeohyracidae', 'Heterohyrax', 'Procaviidae\\nDendrohyrax', 'D. arboreus', 'Embrithopoda', '†Gigantohyrax\\nHeterohyrax', 'H. brucei', 'Titanohyrax', '†Saghatherium\\u2009\\n\\n\\u2009†Titanohyrax', 'zone.[41', 'Gitori', 'Proboscidea', '†Hengduanshanhyrax', 'Leviticus', '†Antilohyrax\\u2009\\n\\n†Megalohyrax\\n\\n  Geniohyiinae  \\t\\n', 'Bush', 'P. capensis', 'Dendrohyrax interfluvialis', 'Hadrian']\n",
            "\n",
            "Places (GPE): ['tapirs', 'Polyphyletic', 'Kenya', 'Tigrinya', 'Mount Kenya', 'Dimaitherium', 'Hyraxes', 'Spain', 'Paenungulata', 'Niger', 'Egypt', 'Rusinga']\n",
            "\n",
            "Organizations: ['†Kvabebihyrax', 'cud', '†Seggeurius', '†Geniohyus', '†Titanohyracidae', 'hyraceum', '†Thyrohyrax', 'מַעֲלֵה', '†Parapliohyrax', 'dugongs.[22', 'D. dorsalis\\n \\n\\nBenin', 'Hyraxes', 'females.[18', '†Titanohyrax', 'bones.[31', 'configuration.[14', 'Gikuyu', 'Procavia', 'foot.[17']\n"
          ]
        }
      ]
    }
  ]
}